{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "159Jng5XyTFi4_GSCUnMKNQVMWTXOLzsO",
      "authorship_tag": "ABX9TyMJkOI7tCGXP+AOIqJpO+4q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swethasrihari/NLP/blob/main/NLP_HW1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYbXzwnpCns1",
        "outputId": "8fdebc56-f03a-4797-8b93-2f93ce9ad0d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "training_path = \"/content/drive/MyDrive/Colab Notebooks/sentiment_train.json\"\n",
        "test_path = \"/content/drive/MyDrive/Colab Notebooks/sentiment_test.json\"\n",
        "\n",
        "train_data = pd.read_json(training_path, lines=True)\n",
        "test_data = pd.read_json(test_path,lines=True)"
      ],
      "metadata": {
        "id": "-LHCmOzHCsdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting review_titles and stars column data from the dataset"
      ],
      "metadata": {
        "id": "CIX-vAbRkfcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_required_columns(dataset):\n",
        "  stars = []\n",
        "  review_title = []\n",
        "  for record in dataset.values:\n",
        "    stars.append(record[3])\n",
        "    review_title.append(record[5])\n",
        "  return stars,review_title"
      ],
      "metadata": {
        "id": "ndp8ObEIC_a_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stars, review_title = extract_required_columns(train_data)\n",
        "test_stars, test_review_title = extract_required_columns(test_data)"
      ],
      "metadata": {
        "id": "MkTKo-O-rfKx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def remove_punctuation(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "    return text"
      ],
      "metadata": {
        "id": "cWKeEOXTo9D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining a function to split the given review into uni/bi/trigrams.."
      ],
      "metadata": {
        "id": "DQCUdR8aEkpa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "\n",
        "def split_into_ngrams(words, n):\n",
        "  grams = []\n",
        "  for i in range(len(words)):\n",
        "    grams.append(list(ngrams(words[i],n)))\n",
        "  return grams\n"
      ],
      "metadata": {
        "id": "CsEjVjuQEh1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing data by removing punctuations, converting into lower case and splitting into words"
      ],
      "metadata": {
        "id": "H2FoD99BtPaZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing_data(review_title):\n",
        "  words = []\n",
        "  for review in review_title:\n",
        "    cleaned_review = (remove_punctuation(review)).lower()\n",
        "    words.append(cleaned_review.split())\n",
        "  return words"
      ],
      "metadata": {
        "id": "FVLh8d6yD7fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_train_review_title = preprocessing_data(review_title)\n",
        "cleaned_test_review_title = preprocessing_data(test_review_title)\n",
        "data = {\"review_title\":cleaned_train_review_title,\n",
        "        \"stars\": stars}\n",
        "df = pd.DataFrame(data)\n",
        "testing_data = {\"review_title\":cleaned_test_review_title,\n",
        "                \"stars\":test_stars}\n",
        "test_df = pd.DataFrame(testing_data)\n",
        "#print(test_df)"
      ],
      "metadata": {
        "id": "EIjd5MrftLDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ngrams(words):\n",
        "  bigrams = split_into_ngrams(words,2)\n",
        "  trigrams = split_into_ngrams(words,3)\n",
        "  return bigrams,trigrams\n",
        "\n"
      ],
      "metadata": {
        "id": "LCyKiiwunO0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bigrams,train_trigrams = get_ngrams(cleaned_train_review_title)\n",
        "test_bigrams,test_trigrams = get_ngrams(cleaned_test_review_title)\n"
      ],
      "metadata": {
        "id": "W6334jHlmx_5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['bigrams'] = train_bigrams\n",
        "df['trigrams'] = train_trigrams\n",
        "test_df['bigrams'] = test_bigrams\n",
        "test_df['trigrams'] = test_trigrams\n",
        "#print(df)"
      ],
      "metadata": {
        "id": "LgkkF_-5m9nW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting the cleaned review title into vector for both train and test data"
      ],
      "metadata": {
        "id": "f1OtHT4Kk8sF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "flattened_train_review_title = [' '.join(review) for review in cleaned_train_review_title]\n",
        "flattened_test_review_title = [' '.join(review) for review in cleaned_test_review_title]\n",
        "vectorizer = TfidfVectorizer()\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)"
      ],
      "metadata": {
        "id": "XrEtKtm6h92d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the data into Logistic Regression Model"
      ],
      "metadata": {
        "id": "h5wqRpaVk0xG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "y_train = stars\n",
        "y_test = test_stars\n",
        "reg = LogisticRegression().fit(x_train, y_train)\n",
        "y_pred = reg.predict(x_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAKT8z3VkUFY",
        "outputId": "30b4fc6a-a5f8-4f79-c188-d7debd6d08c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Logistic Regression Classifier Metrics\")\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJoAlgYTknE1",
        "outputId": "968513a1-724f-4f93-944b-3d2ab1b85435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier Metrics\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.93      0.92      0.93      1000\n",
            "           5       0.92      0.93      0.93      1000\n",
            "\n",
            "    accuracy                           0.93      2000\n",
            "   macro avg       0.93      0.93      0.93      2000\n",
            "weighted avg       0.93      0.93      0.93      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "print(\"Confusion Matrix For Logistic Regression Model\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENEIpcM2lYl3",
        "outputId": "d1b4fb6c-fb7a-43a8-8b23-ca4b084fb0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix For Logistic Regression Model\n",
            "[[924  76]\n",
            " [ 72 928]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomizing and reducing the length of the dataset to 10000\n"
      ],
      "metadata": {
        "id": "CM6cr91XSZgf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = df[['stars','review_title']]\n",
        "\n",
        "import random\n",
        "reduced_train = data.sample(n=10000)\n"
      ],
      "metadata": {
        "id": "0TssNpKzCTNK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_train_review_title = [' '.join(review) for review in reduced_train['review_title']]\n",
        "flattened_test_review_title = [' '.join(review) for review in test_df['review_title']]\n"
      ],
      "metadata": {
        "id": "iWU14-cchpgk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_reduced_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)\n",
        "\n",
        "y_reduced_train = reduced_train['stars']\n",
        "y_test = test_stars\n",
        "reg = LogisticRegression().fit(x_reduced_train, y_reduced_train)\n",
        "y_pred = reg.predict(x_test)\n",
        "\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Logistic Regression Classifier Metrics for 10000 training data\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix For Logistic Regression Model\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCAmQ7vUq3Bu",
        "outputId": "14d60732-1024-41b8-8070-39b49f67a523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier Metrics for 10000 training data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.90      0.91      1000\n",
            "           5       0.90      0.92      0.91      1000\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.91      0.91      0.91      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n",
            "Confusion Matrix For Logistic Regression Model\n",
            "[[901  99]\n",
            " [ 84 916]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing the dataset to 5000"
      ],
      "metadata": {
        "id": "CCeFB3kEVJRC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train = data.sample(n=5000)\n",
        "flattened_train_review_title = [' '.join(review) for review in reduced_train['review_title']]\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)\n",
        "y_reduced_train = reduced_train['stars']\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG4cyWU4VIQx",
        "outputId": "73ecd3c1-179b-4e2a-b7e4-9b1a9565dd72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 3318)\n",
            "(2000, 3318)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg = LogisticRegression().fit(x_train, y_reduced_train)\n",
        "y_pred = reg.predict(x_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Logistic Regression Classifier Metrics for 5000 training data\")\n",
        "print(report)\n",
        "print(\"Confusion Matrix For Logistic Regression Model\")\n",
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrUhxYc_VVAJ",
        "outputId": "a775d0cd-fda1-4c04-9e17-4641867affbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Classifier Metrics for 5000 training data\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.88      0.90      0.89      1000\n",
            "           5       0.90      0.88      0.89      1000\n",
            "\n",
            "    accuracy                           0.89      2000\n",
            "   macro avg       0.89      0.89      0.89      2000\n",
            "weighted avg       0.89      0.89      0.89      2000\n",
            "\n",
            "Confusion Matrix For Logistic Regression Model\n",
            "[[903  97]\n",
            " [123 877]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes Model"
      ],
      "metadata": {
        "id": "FAaPTeursXvu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_train_review_title = [' '.join(review) for review in cleaned_train_review_title]\n",
        "\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)"
      ],
      "metadata": {
        "id": "z5oS805NQo6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "clf = MultinomialNB()\n",
        "clf.fit(x_train, y_train)"
      ],
      "metadata": {
        "id": "LUejt4ssrhZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = clf.predict(x_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6_ZLIK_sgqz",
        "outputId": "6ba4d311-d215-4c3f-d50f-13a2bd2aaead"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.92      0.91      1000\n",
            "           5       0.92      0.90      0.91      1000\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.91      0.91      0.91      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3UXOt3VtAyB",
        "outputId": "bb170a41-291d-452e-af7a-be920213171e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[923  77]\n",
            " [104 896]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Randomizing and reducing the length of the dataset to 10000\n"
      ],
      "metadata": {
        "id": "PRdagpR2Sbkx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_train_review_title = [' '.join(review) for review in reduced_train['review_title']]\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CNMNiFozSKLr",
        "outputId": "7ae00b74-53cf-4101-efa5-7b8d73b58f88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 4952)\n",
            "(2000, 4952)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, y_reduced_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPK0ePqaS01f",
        "outputId": "ac8a1b62-598d-47ad-dc13-1e32b7755268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.89      0.91      0.90      1000\n",
            "           5       0.91      0.89      0.90      1000\n",
            "\n",
            "    accuracy                           0.90      2000\n",
            "   macro avg       0.90      0.90      0.90      2000\n",
            "weighted avg       0.90      0.90      0.90      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lUxXvugKU6q6",
        "outputId": "b25b427e-686c-402b-d612-12b7ada881b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[918  82]\n",
            " [139 861]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reducing the dataset to 50000"
      ],
      "metadata": {
        "id": "9uSLOwCIUHD2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train = data.sample(n=50000)\n",
        "flattened_train_review_title = [' '.join(review) for review in reduced_train['review_title']]\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)\n",
        "y_reduced_train = reduced_train['stars']\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sn4GoAyQTAh3",
        "outputId": "e8de3835-7d94-4d1e-f344-29836c538312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 11427)\n",
            "(2000, 11427)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, y_reduced_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65RCYy01UQRG",
        "outputId": "e20243de-75ad-4b13-9fda-b756aaa8c231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.90      0.91      0.91      1000\n",
            "           5       0.91      0.90      0.91      1000\n",
            "\n",
            "    accuracy                           0.91      2000\n",
            "   macro avg       0.91      0.91      0.91      2000\n",
            "weighted avg       0.91      0.91      0.91      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZXIaz9yU8j9",
        "outputId": "fde4d448-ab5c-414d-81de-1d8f10ae1e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[918  82]\n",
            " [139 861]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "reducing the dataset to 5000"
      ],
      "metadata": {
        "id": "0l1UJkr4Uo3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reduced_train = data.sample(n=5000)\n",
        "flattened_train_review_title = [' '.join(review) for review in reduced_train['review_title']]\n",
        "x_train = vectorizer.fit_transform(flattened_train_review_title)\n",
        "x_test = vectorizer.transform(flattened_test_review_title)\n",
        "y_reduced_train = reduced_train['stars']\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnFIgQW5UW0X",
        "outputId": "e4536298-5395-490e-d5f7-5140544c5367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 3228)\n",
            "(2000, 3228)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clf.fit(x_train, y_reduced_train)\n",
        "y_pred = clf.predict(x_test)\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(report)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fn6XE5AAUtVK",
        "outputId": "20a54c99-e772-477c-e2c0-d7ef5bebc148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.87      0.92      0.89      1000\n",
            "           5       0.91      0.86      0.89      1000\n",
            "\n",
            "    accuracy                           0.89      2000\n",
            "   macro avg       0.89      0.89      0.89      2000\n",
            "weighted avg       0.89      0.89      0.89      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(confusion_matrix(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfxDdCBOUvRd",
        "outputId": "491ef890-9593-404c-ec8e-90641e892aa1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[918  82]\n",
            " [139 861]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "* For Naive Bayes there is not much difference in the confusion matrix when we decrease the number of rows in a dataset.\n",
        "*   Very slight difference in Precision, recall, F!-score and accuracy.\n",
        "\n",
        "\n",
        "*   For Logistic regression, There was a huge difference in the confussion matrix, as we reduce the number of rows in the dataset, the values of true possitive and true negative decreases and the values of false possitive and false negative increases.\n",
        "*   There was around 5% difference between the different metrices of datasets of 80000 and 5000 rows.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "r-SrJCa7XHVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resources Used:\n",
        "\n",
        "\n",
        "ChatGPT\n",
        "\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
        "\n",
        "\n",
        "Stack Overflow"
      ],
      "metadata": {
        "id": "JTo_tS7iZrRT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!sudo apt-get update\n",
        "#!sudo apt-get install texlive-xetex texlive-fonts-recommended texlive-latex-recommended\n",
        "#!pip install nbconvert\n",
        "!jupyter nbconvert --to pdf \"/content/drive/MyDrive/Colab Notebooks/NLP_HW1.ipynb\"\n",
        "# The semicolon below suppresses this cell's output\n",
        "# This is to prevent 10 pages of installation messages from printing to the pdf\n",
        ";"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "75ZkYe0Go7E0",
        "outputId": "83635619-1b0a-4ba2-b9f0-12862ff17bed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[NbConvertApp] Converting notebook /content/drive/MyDrive/Colab Notebooks/NLP_HW1.ipynb to pdf\n",
            "[NbConvertApp] Writing 53929 bytes to notebook.tex\n",
            "[NbConvertApp] Building PDF\n",
            "[NbConvertApp] Running xelatex 3 times: ['xelatex', 'notebook.tex', '-quiet']\n",
            "[NbConvertApp] Running bibtex 1 time: ['bibtex', 'notebook']\n",
            "[NbConvertApp] WARNING | bibtex had problems, most likely because there were no citations\n",
            "[NbConvertApp] PDF successfully created\n",
            "[NbConvertApp] Writing 51171 bytes to /content/drive/MyDrive/Colab Notebooks/NLP_HW1.pdf\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2TTiqIW3GKzF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}